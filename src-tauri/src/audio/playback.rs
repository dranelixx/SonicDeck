//! Audio playback stream creation and sample writing
//!
//! Handles cpal stream creation with sample rate conversion using linear interpolation.

use std::sync::{Arc, Mutex};
use cpal::traits::{DeviceTrait, StreamTrait};
use cpal::{Device, Stream};

use super::{AudioData, AudioError};

/// Create and start a playback stream on a specific device
pub fn create_playback_stream(
    device: &Device,
    audio_data: Arc<AudioData>,
    volume: Arc<Mutex<f32>>,
) -> Result<Stream, AudioError> {
    let config = device.default_output_config()
        .map_err(|e| AudioError::DeviceConfig(e.to_string()))?;

    let output_sample_rate = config.sample_rate().0;
    let channels = config.channels() as usize;
    let sample_index = Arc::new(Mutex::new(0.0f64)); // Float for smooth resampling

    // Calculate sample rate ratio for resampling
    let rate_ratio = audio_data.sample_rate as f64 / output_sample_rate as f64;

    let stream = match config.sample_format() {
        cpal::SampleFormat::F32 => {
            let audio_data = audio_data.clone();
            let sample_index = sample_index.clone();
            let volume = volume.clone();
            device.build_output_stream(
                &config.into(),
                move |data: &mut [f32], _: &cpal::OutputCallbackInfo| {
                    let vol = *volume.lock().unwrap();
                    write_audio_f32(data, &audio_data, &sample_index, vol, channels, rate_ratio);
                },
                |err| eprintln!("Stream error: {}", err),
                None,
            )
        }
        cpal::SampleFormat::I16 => {
            let audio_data = audio_data.clone();
            let sample_index = sample_index.clone();
            let volume = volume.clone();
            device.build_output_stream(
                &config.into(),
                move |data: &mut [i16], _: &cpal::OutputCallbackInfo| {
                    let vol = *volume.lock().unwrap();
                    write_audio_i16(data, &audio_data, &sample_index, vol, channels, rate_ratio);
                },
                |err| eprintln!("Stream error: {}", err),
                None,
            )
        }
        cpal::SampleFormat::U16 => {
            let audio_data = audio_data.clone();
            let sample_index = sample_index.clone();
            let volume = volume.clone();
            device.build_output_stream(
                &config.into(),
                move |data: &mut [u16], _: &cpal::OutputCallbackInfo| {
                    let vol = *volume.lock().unwrap();
                    write_audio_u16(data, &audio_data, &sample_index, vol, channels, rate_ratio);
                },
                |err| eprintln!("Stream error: {}", err),
                None,
            )
        }
        _ => return Err(AudioError::UnsupportedFormat),
    }
    .map_err(|e| AudioError::StreamBuild(e.to_string()))?;

    stream.play()
        .map_err(|e| AudioError::StreamStart(e.to_string()))?;

    Ok(stream)
}

/// Write audio data to f32 output buffer with resampling (linear interpolation)
fn write_audio_f32(
    output: &mut [f32],
    audio_data: &AudioData,
    sample_index: &Arc<Mutex<f64>>,
    volume: f32,
    output_channels: usize,
    rate_ratio: f64,
) {
    let mut index = sample_index.lock().unwrap();
    let input_channels = audio_data.channels as usize;
    let max_frame = (audio_data.samples.len() / input_channels) as f64;
    
    // Apply square root volume curve with base attenuation
    // Base multiplier of 0.2 for safe default volume (20% of full amplitude)
    let scaled_volume = volume.sqrt() * 0.2;

    for frame in output.chunks_mut(output_channels) {
        if *index >= max_frame - 1.0 {
            // End of audio - silence
            for sample in frame.iter_mut() {
                *sample = 0.0;
            }
            continue;
        }

        // Linear interpolation between samples
        let frame_idx = *index as usize;
        let frac = *index - frame_idx as f64; // Fractional part for interpolation

        for (ch, sample) in frame.iter_mut().enumerate() {
            let ch_idx = ch % input_channels;
            let idx1 = frame_idx * input_channels + ch_idx;
            let idx2 = (frame_idx + 1) * input_channels + ch_idx;

            if idx2 < audio_data.samples.len() {
                // Linear interpolation: value = sample1 + (sample2 - sample1) * frac
                let sample1 = audio_data.samples[idx1];
                let sample2 = audio_data.samples[idx2];
                *sample = (sample1 + (sample2 - sample1) * frac as f32) * scaled_volume;
            } else if idx1 < audio_data.samples.len() {
                *sample = audio_data.samples[idx1] * scaled_volume;
            } else {
                *sample = 0.0;
            }
        }

        *index += rate_ratio;
    }
}

/// Write audio data to i16 output buffer with resampling (linear interpolation)
fn write_audio_i16(
    output: &mut [i16],
    audio_data: &AudioData,
    sample_index: &Arc<Mutex<f64>>,
    volume: f32,
    output_channels: usize,
    rate_ratio: f64,
) {
    let mut index = sample_index.lock().unwrap();
    let input_channels = audio_data.channels as usize;
    let max_frame = (audio_data.samples.len() / input_channels) as f64;
    
    // Apply square root volume curve with base attenuation
    // Base multiplier of 0.2 for safe default volume (20% of full amplitude)
    let scaled_volume = volume.sqrt() * 0.2;

    for frame in output.chunks_mut(output_channels) {
        if *index >= max_frame - 1.0 {
            // End of audio - silence
            for sample in frame.iter_mut() {
                *sample = 0;
            }
            continue;
        }

        // Linear interpolation between samples
        let frame_idx = *index as usize;
        let frac = *index - frame_idx as f64;

        for (ch, sample) in frame.iter_mut().enumerate() {
            let ch_idx = ch % input_channels;
            let idx1 = frame_idx * input_channels + ch_idx;
            let idx2 = (frame_idx + 1) * input_channels + ch_idx;

            let value = if idx2 < audio_data.samples.len() {
                let sample1 = audio_data.samples[idx1];
                let sample2 = audio_data.samples[idx2];
                (sample1 + (sample2 - sample1) * frac as f32) * scaled_volume
            } else if idx1 < audio_data.samples.len() {
                audio_data.samples[idx1] * scaled_volume
            } else {
                0.0
            };
            *sample = (value * 32767.0) as i16;
        }

        *index += rate_ratio;
    }
}

/// Write audio data to u16 output buffer with resampling (linear interpolation)
fn write_audio_u16(
    output: &mut [u16],
    audio_data: &AudioData,
    sample_index: &Arc<Mutex<f64>>,
    volume: f32,
    output_channels: usize,
    rate_ratio: f64,
) {
    let mut index = sample_index.lock().unwrap();
    let input_channels = audio_data.channels as usize;
    let max_frame = (audio_data.samples.len() / input_channels) as f64;
    
    // Apply square root volume curve with base attenuation
    // Base multiplier of 0.2 for safe default volume (20% of full amplitude)
    let scaled_volume = volume.sqrt() * 0.2;

    for frame in output.chunks_mut(output_channels) {
        if *index >= max_frame - 1.0 {
            // End of audio - silence
            for sample in frame.iter_mut() {
                *sample = 32768;
            }
            continue;
        }

        // Linear interpolation between samples
        let frame_idx = *index as usize;
        let frac = *index - frame_idx as f64;

        for (ch, sample) in frame.iter_mut().enumerate() {
            let ch_idx = ch % input_channels;
            let idx1 = frame_idx * input_channels + ch_idx;
            let idx2 = (frame_idx + 1) * input_channels + ch_idx;

            let value = if idx2 < audio_data.samples.len() {
                let sample1 = audio_data.samples[idx1];
                let sample2 = audio_data.samples[idx2];
                (sample1 + (sample2 - sample1) * frac as f32) * scaled_volume
            } else if idx1 < audio_data.samples.len() {
                audio_data.samples[idx1] * scaled_volume
            } else {
                0.0
            };
            *sample = ((value + 1.0) * 32767.5) as u16;
        }

        *index += rate_ratio;
    }
}
